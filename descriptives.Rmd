
---
title: "Descriptive analyses"
#bibliography: references.bib
author: "Bas Hofstra"
---

```{r, globalsettings, echo=FALSE, warning=FALSE, results='hide'}
library(knitr)

knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=100),tidy=TRUE, warning = FALSE, message = FALSE,comment = "#>", cache=TRUE, class.source=c("test"), class.output=c("test2"))
options(width = 100)
rgl::setupKnitr()



colorize <- function(x, color) {sprintf("<span style='color: %s;'>%s</span>", color, x) }

```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('top', 'right'))
#klippy::klippy(color = 'darkred')
#klippy::klippy(tooltip_message = 'Click to copy', tooltip_success = 'Done')
```

Last compiled on `r format(Sys.time(), '%B, %Y')`

<br>

----

This is the code with which we render our descriptive analyses

<br>

----

# Initatiating R environment

Start out with a custom function to load a set of required packages.
  
```{r pack, eval=TRUE}
# packages and read data
rm(list = ls())

# (c) Jochem Tolsma
fpackage.check <- function(packages) {
  lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  })
}
packages = c("haven", "coda", "matrixStats", "parallel", "MASS", "doParallel", "dplyr", "cowplot", 
             "tidyverse", "naniar", "dotwhisker" ,"gt", "reshape2", "VGAM", "expss", "Hmisc",
             "poweRlaw", "fitdistrplus", "grid", "ggplotify")
fpackage.check(packages)
rm(packages)
load("data/dutch_netsize_analyses.rda")
```
<br>

----

# Descriptives independent variables

The code below generates the descriptive values which are used for Tables 1 and 2.
  

```{r descind, eval = TRUE}




# descriptive table not automated: TABLE 1
table(df$work)
psych::describe(df$work)
psych::describe(df$hhsize)


table(df$migr3)
# 1 Maj
# 2 west
# 3 nonwest

table(df$agecat)

table(df$income)
# 1 < modal
# 2 > modal
# 3 unknown

psych::describe(df$worthhouse)


table(df$woman)
psych::describe(df$woman)

table(df$opl)
# 1 prim/sec
# 2 lower tert
# 3 higher tert

#psych::describe(df$neighdens)


# this is for the correlation table
#df$educ3 <- df$opl
#df$educ3 <- as.numeric(as.character(df$educ3))

cor(as.matrix(df[df$income!=3,c("income","worthhouse")]))

#rcorr(as.matrix(df[,c("work", "hhsize", "leeftijd10", "woman", "educ3", "neighdens", "worthhouse" )]), type = "pearson")

```

<br>

----

# Comparing naive estimations

The code below generates Figure 1 from the paper and runs a number of correlations found on page X.
  

```{r naicomps, eval = TRUE}

comps <- gather(df[, c("nsize_naive", "nsize_b1b2", "nsize_b3", "nsize_n1", "nsize_n2", "nsize_n3", "nsize_n123")])

comparisons <- ggplot(comps[comps$value < 2000, ], aes(x=value, color = key)) + 
  geom_density(size = 0.5) + 
  theme_minimal() +
  labs(x = "Network size estimate", y = "Density") +
  scale_color_manual(name = "Estimation scenario", 
                      breaks = c("nsize_naive", "nsize_b1b2", "nsize_b3", "nsize_n1", "nsize_n2", "nsize_n3", "nsize_n123"), 
                       labels = c("Naive estimator: all X's", 
                                  "Battery 1: Tert. educ., elec vehicle, etc.", 
                                  "Battery 2: all names", 
                                  "Names 1: Sophie, Anna, Thomas, Willem", 
                                  "Names 2: Julia, Elisabeth, Max, Ali",
                                  "Names 3: Sanne, Cornelia, Kevin, Mohammed",
                                  "Names1+2+3"),
                     values = c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                          "#0072B2", "#D55E00", "#CC79A7", "darkgrey"))

# save
ggsave("output/comparisons.pdf", plot = comparisons, device = "pdf",
       scale = 1, width = 10, height = 5.5, units = c("in"),
       dpi = "retina")



# # correlation battery 1 and 2
# cor(df$nsize_b1, df$nsize_b2)
# 
# # correlation battery 1 and all
# cor(df$nsize_b1, df$nsize_naive)

# correlation battery 1+2 and all
cor(df$nsize_b1b2, df$nsize_naive)

# correlation battery 3 (names) and all
cor(df$nsize_b3, df$nsize_naive)

# correlation names 1 and all
cor(df$nsize_n1, df$nsize_naive)

# correlation names 2 and all
cor(df$nsize_n2, df$nsize_naive)

# correlation names 3 and all
cor(df$nsize_n3, df$nsize_naive)

# correlation names 123 and all
cor(df$nsize_n123, df$nsize_naive)

# sample 5 columns of scenarios and correlate with naive estimand
set.seed(1987)
sample(13:183, 5)

# correlation scenario 85 and naive
cor(df$nsize_naive, df[, 85])

# correlation scenario 36 and naive
cor(df$nsize_naive, df[, 36])

# correlation scenario 150 and naive
cor(df$nsize_naive, df[, 150])

# correlation scenario 14 and naive
cor(df$nsize_naive, df[, 14])

# correlation scenario 125 and naive
cor(df$nsize_naive, df[, 125])

comparisons

```




<br>

----

# Comparing Bayesian estimations

The code below generates Figure 2 from the paper associated with the text on page X.
  
```{r bayecomps, eval = TRUE}

netsizes <- read.table(file = "data/dutch_netsize_desc.txt")

# VIZ of netsize
netsize_l <- gather(netsizes)
dens1 <- ggplot(netsize_l[netsize_l$value < 2000,], aes(x=value, color = key)) + 
  geom_density(alpha = .2, size = 0.1) + 
  theme_minimal() + 
  theme(legend.position = "none") +
  labs(x = "Network size estimate", y = "Density") +
  geom_vline(xintercept=as.numeric(psych::describe(netsize_l[, 2])[3]), color = "darkgrey", linetype = 2) +
  geom_vline(xintercept=as.numeric(psych::describe(netsize_l[, 2])[5]), color = "darkgrey", linetype = 2) +
  annotate("text", x = 490, y = 0.0004, color = "darkgrey", angle = 90, 
           label = paste0("Mean = ", round(as.numeric(psych::describe(netsize_l[, 2])[3]), digits = 0))) +
  annotate("text", x = 340, y = 0.0004, color = "darkgrey", angle = 90, 
           label = paste0("Median = ", round(as.numeric(psych::describe(netsize_l[, 2])[5]), digits = 0))) +
  ggtitle("B) Distribution of network sizes, all scenarios")


# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
  cormat[upper.tri(cormat)] <- NA
  return(cormat)
}
mat <- cor(netsizes)
lower_tri <- get_lower_tri(mat)
melted_cormat <- reshape2::melt(lower_tri) # data.table also has melt funciton that won't work on matrices
melted_cormat$Var2 <- as.character(melted_cormat$Var2)
melted_cormat$Var1 <- as.character(melted_cormat$Var1)
melted_cormat <- melted_cormat[!melted_cormat$Var2 == melted_cormat$Var1,]
melted_cormat <- melted_cormat[!is.na(melted_cormat$value), ]

# Viz of correlations between netsize estimates
dens2 <- ggplot(melted_cormat, aes(x=value)) + 
  geom_density(size = 0.3) + 
  xlim(0.915, 1) + 
  theme_minimal() + 
  labs(x="Pearson correlation", y = "Density") +
  geom_vline(xintercept = .95, color = "darkgrey", linetype = 2) +
  ggtitle("A) Distributions of correlations between network size scenarios")  +
  geom_segment(x = 0.95, y = 125, xend = .99, yend = 125, linetype = 2, color = "darkgrey",
                arrow = arrow(length = unit(0.25, "cm")))  +
  annotate("text", x = .97, y = 135, color = "darkgrey", angle = 0, 
           label = paste0(round(nrow(melted_cormat[melted_cormat$value > .95, ])/nrow(melted_cormat)*100, digits = 1),"% of correlations are > .95"))

# lay 'm out on the grid           
denses <- plot_grid(dens2, dens1, nrow = 1) 

# save
ggsave("output/densities.pdf", plot = denses, device = "pdf",
       scale = 1, width = 12, height = 4, units = c("in"),
       dpi = "retina")

denses
```

<br>

----

# Distributional fit

We now fit a "complementary cumulative degree distribution" and check how it fits.


```{r ccdf, eval = TRUE}


df$netsize <- round(rowSums(df[,c(14:185)]) / length(14:185), 0)
df <- df[!df$netsize > 5000, ]
degrees <- df$netsize

degr_pl <- displ$new(degrees) # create a discrete powerlaw distribution object 

# with estimating lower threshold:
degr_ln_xmin <- dislnorm$new(degrees)
est = estimate_xmin(degr_ln_xmin)
degr_ln_xmin$setXmin(est)

# without lower threshold:
degr_ln_noxmin <-fitdist(degrees, "lnorm")

# Goodness of fit for lognorm, no xmin:
gof_degr_ln_noxmin <- gofstat(degr_ln_noxmin, fitnames = "Log-normal", discrete = TRUE)

x_seq <- seq(0, max(degrees), length = 500)

# For plotting the no x_min version of LN
ln_fit_ccdf <- 1 - plnorm(x_seq, meanlog = degr_ln_noxmin$estimate[1], sdlog =  degr_ln_noxmin$estimate[2])

# capture data that make the plot
pd1 <- plot(degr_pl, draw = F) # plot data 1, empirical distr
pd2 <- lines(degr_ln_xmin, draw = F) # plot data 2 no xmin
pd3 <- data.frame(cbind(x_seq, ln_fit_ccdf)) # plot data 3 with xmin

# now render it a ggplot
ccdfplot <- ggplot() + 
              geom_point(data=pd1, aes(x = x, y = y), shape=1) + 
              geom_line(data=pd2, aes(x = x, y = y, color = "Log-normal fit, w/ x_min")) +
              geom_line(data=pd3, aes(x = x_seq, y = ln_fit_ccdf, color = "Log-normal fit, no x_min")) +
              labs(x="Extended network size", y="CCDF") + 
              scale_color_manual(name = "Fit", values = c("Log-normal fit, w/ x_min" = "green", 
                                                          "Log-normal fit, no x_min" = "purple")) +
              theme_bw() +
              theme(legend.position = c(0.2, 0.2)) +
              scale_x_log10(breaks = c(50,100,200,500,1000,2000), limits = c(min(pd1$x), max(pd1$x))) + scale_y_log10() 

# save
ggsave("output/ccdfplot.pdf", plot = ccdfplot, device = "pdf",
       scale = 1, width = 6, height = 4, units = c("in"),
       dpi = "retina")

### original plot in Base r
# # Plotting two versions of LN
# plot(degr_pl, xlab="Number of contacts", ylab="CCDF")
# lines(degr_ln_xmin, col = "green", lwd = 2)
# lines(x_seq, ln_fit_ccdf, col = "purple", lwd = 2)
# legend(x = "bottomleft",
#        legend = c("Log-normal fit, w/ x_min",
#                   "Log-normal fit, no x_min" 
#                   ),
#        col = c("green","purple"),
#        lwd = 2)
ccdfplot
```










